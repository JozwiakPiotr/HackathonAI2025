{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74a4ffb2-ecb5-4bad-94f6-2cb8204e1cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e9abc88-10b3-4c63-b71a-1a3c076b5993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OLLAMA_BASE_URL=http://172.20.3.133:11434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://172.20.3.133:11434'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env OLLAMA_BASE_URL=http://172.20.3.133:11434\n",
    "%env OLLAMA_BASE_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e2c72b6-7d2f-47b2-b93b-35a5dc065900",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "def setup_openai(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs = loader.load_and_split()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "    embeddigns = OpenAIEmbeddings()\n",
    "    vector_store = FAISS.from_documents(chunks, embeddigns)\n",
    "    retriever = vector_store.as_retriever()\n",
    "    llm = ChatOpenAI(temperature=0,model_name='gpt-4o')\n",
    "    qa_chain=RetrievalQA.from_chain_type(llm,retriever=retriever)\n",
    "    return qa_chain\n",
    "\n",
    "def setup_ollama(file_path):\n",
    "    os.environ[\"OLLAMA_BASE_URL\"] = \"http://172.20.3.133:11434\"\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs = loader.load_and_split()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_documents(docs)\n",
    "    embeddings = OllamaEmbeddings(\n",
    "        model=\"llama3\",\n",
    "        base_url=\"http://172.20.3.133:11434\"\n",
    "    )\n",
    "    vector_store = FAISS.from_documents(chunks, embeddings)\n",
    "    retriever = vector_store.as_retriever()\n",
    "    llm = OllamaLLM(\n",
    "        model=\"llama3\",\n",
    "        base_url=\"http://172.20.3.133:11434\"\n",
    "    )\n",
    "    qa_chain=RetrievalQA.from_chain_type(llm,retriever=retriever)\n",
    "    return qa_chain    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7b97944-8138-4735-993e-4b411a942117",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OllamaLLM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m qa_chain = \u001b[43msetup_ollama\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mProgramista_103.pdf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36msetup_ollama\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m     24\u001b[39m vector_store = FAISS.from_documents(chunks, embeddings)\n\u001b[32m     25\u001b[39m retriever = vector_store.as_retriever()\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m llm = \u001b[43mOllamaLLM\u001b[49m(\n\u001b[32m     27\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mllama3\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     28\u001b[39m     base_url=\u001b[33m\"\u001b[39m\u001b[33mhttp://172.20.3.133:11434\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     29\u001b[39m )\n\u001b[32m     30\u001b[39m qa_chain=RetrievalQA.from_chain_type(llm,retriever=retriever)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m qa_chain\n",
      "\u001b[31mNameError\u001b[39m: name 'OllamaLLM' is not defined"
     ]
    }
   ],
   "source": [
    "qa_chain = setup_ollama('Programista_103.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce827e8-b4ef-4cd5-bd0e-fa420c7903bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain.invoke('ile lat ma autor artyku≈Çu o Precision Time Protocol')['result']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
